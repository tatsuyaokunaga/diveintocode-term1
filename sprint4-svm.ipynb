{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提知識の説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMとは分類と回帰の両方に利用可能な教師あり学習のモデルです。  \n",
    "2次元の特徴量を持つデータに対し、線形モデルによって2クラス分類を行うことを考えます。  \n",
    "学習データのプロットされた平面上に直線を引いて領域を2つに分ける作業で、分類とは線を引くことであり、SVMはうまい具合に線を引く方法です。  \n",
    "SVMではどの点にも被らないようにできるだけ広い帯を引こうとします。\n",
    "- メリット  \n",
    "他のモデルと比較して高い識別性能が得られる  \n",
    "- デメリット  \n",
    "データの前処理やパラメーターの調整、結果の解釈が難しい  \n",
    "- 特徴\n",
    "「マージン」という「距離のような概念」の最大化を目的としている。  \n",
    "平均や分散を使わないので新しいデータが入ってきても全体の再計算は不要。  \n",
    "線形分離が不可能な場合は、「非線形変換を施したうえでより高次元特徴空間に写像」することで対応できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMにおけるカーネルとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形分離ができない場合、データをある関数により、より高次元空間に埋め込むことで、SVMを使って線形分離にすることができる。このときに使う関数をカーネルといいます。  \n",
    "SVMには以下のカーネルが用意されています。  \n",
    "- linear（線形カーネル）\n",
    "- poly（多項式カーネル）\n",
    "- rbf（RBFカーネル）\n",
    "- sigmoid（シグモイドカーネル）\n",
    "- precomputed（事前に計算したものを利用する）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形回帰やロジスティック回帰との比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰やロジスティック回帰は、目的関数を最小化するために各パラメータで偏微分した式を最急降下法の式に導入しました。  \n",
    "一方、SVMでは最急降下法は使うが、目的関数の最小値を求める際にベクトルの内積を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ・セットの用意\n",
    "UCIのBreast Cancer Wisconsin (Diagnostic) Data Setを使用  \n",
    "[breast-cancer-wisconsin.data](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Introduction\n",
    "\n",
    "このデータ分析レポートでは、Breast Cancer Wisconsin (Diagnostic)のデータセットを使用して、SVMアルゴリズムによるモデルを構築し、乳がんかそうではないかを分類するために、データ探索を視覚的に行ないます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 各特徴量はUCIのBreast Cancer Wisconsin (Diagnostic) Data Setの公式HP内の記載内容を参照します。\n",
    ">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29  \n",
    "1）ID番号  \n",
    "2）診断（M =悪性、B =良性）  \n",
    "3-32）  \n",
    "10個の実数値の特徴量が各セルの核について計算されます。  \n",
    "a）半径（中心から周囲の点までの距離の平均）  \n",
    "b）テクスチャ（グレースケール値の標準偏差）  \n",
    "c）周囲  \n",
    "d）面積  \n",
    "e）滑らかさ（半径の長さの局所的変化）  \n",
    "f）コンパクト性（周囲^ 2 /面積-1.0）  \n",
    "g）凹み（輪郭の凹部の程度）  \n",
    "h）凹点（輪郭の凹部の数）  \n",
    "i）対称性  \n",
    "j）フラクタル次元（「海岸線近似」-1）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"input/bcwd.txt\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カラム名を下記のURLを参照して数字の代わりに文字列を埋めていきます。    >https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={0:'id',1: 'diagnosis',2: 'radius_mean', 3:'texture_mean', 4:'perimeter_mean',\n",
    "       5:'area_mean', 6:'smoothness_mean',7: 'compactness_mean',8: 'concavity_mean',\n",
    "       9:'concave points_mean',10: 'symmetry_mean', 11:'fractal_dimension_mean',\n",
    "       12:'radius_se', 13:'texture_se',14: 'perimeter_se',15: 'area_se',16: 'smoothness_se',\n",
    "      17: 'compactness_se',18: 'concavity_se',19: 'concave points_se',20: 'symmetry_se',\n",
    "       21:'fractal_dimension_se',22: 'radius_worst',23: 'texture_worst',\n",
    "       24:'perimeter_worst', 25:'area_worst',26: 'smoothness_worst',\n",
    "       27:'compactness_worst',28: 'concavity_worst',29: 'concave points_worst',\n",
    "      30: 'symmetry_worst',31: 'fractal_dimension_worst',})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2列目はラベルになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カラム数は32（ID、診断、特徴量数：30）  \n",
    "IDが整数値、診断はカテゴリカルデータ、特徴量は小数値  \n",
    "データ数は569  \n",
    "欠損値なし  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idは診断結果と関係がないため削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_y=df.diagnosis \n",
    "ax=sns.countplot(df_y,label='Count')\n",
    "B,M =df_y.value_counts()\n",
    "print('良性の人数: ',B)\n",
    "print('悪性の人数: ',M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "診断（M =悪性、B =良性）\n",
    "良性357例、悪性212例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に腫瘍の半径が診断結果（MとB）にどのように関係しているのかヒストグラムでプロットして確認します。平均値と最悪（最大値）値をそれぞれ表示しています。\n",
    "半径の数値が小さい方にBの人数が固まっていて、反対に半径大きくなるほどMの人数が増えていき、ある値からはMのみになります。半径は診断結果への影響が大きいと考えられます。  \n",
    "また平均値より最悪（最大値）値の方が顕著に傾向が表れています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(10,6))\n",
    "m = plt.hist(df[df[\"diagnosis\"] == \"M\"].radius_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\n",
    "b = plt.hist(df[df[\"diagnosis\"] == \"B\"].radius_mean,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Radius Mean Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Radius Mean for Bening and Malignant Tumors\")\n",
    "plt.show()\n",
    "frequent_malignant_radius_mean = m[0].max()\n",
    "index_frequent_malignant_radius_mean = list(m[0]).index(frequent_malignant_radius_mean)\n",
    "most_frequent_malignant_radius_mean = m[1][index_frequent_malignant_radius_mean]\n",
    "print(\"Most frequent malignant radius mean is: \",most_frequent_malignant_radius_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(10,6))\n",
    "m = plt.hist(df[df[\"diagnosis\"] == \"M\"].radius_worst,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\n",
    "b = plt.hist(df[df[\"diagnosis\"] == \"B\"].radius_worst,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Radius Worst Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Radius Worst for Bening and Malignant Tumors\")\n",
    "plt.show()\n",
    "frequent_malignant_radius_worst = m[0].max()\n",
    "index_frequent_malignant_radius_worst = list(m[0]).index(frequent_malignant_radius_worst)\n",
    "most_frequent_malignant_radius_worst = m[1][index_frequent_malignant_radius_worst]\n",
    "print(\"Most frequent malignant radius worst is: \",most_frequent_malignant_radius_worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は診断結果と腫瘍部分の面積の平均値area_meanとの関係性をヒストグラムで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(10,6))\n",
    "m = plt.hist(df[df[\"diagnosis\"] == \"M\"].area_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\n",
    "b = plt.hist(df[df[\"diagnosis\"] == \"B\"].area_mean,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Area Mean Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Area Mean for Bening and Malignant Tumors\")\n",
    "plt.show()\n",
    "frequent_malignant_area_mean = m[0].max()\n",
    "index_frequent_malignant_area_mean = list(m[0]).index(frequent_malignant_area_mean)\n",
    "most_frequent_malignant_area_mean = m[1][index_frequent_malignant_area_mean]\n",
    "print(\"Most frequent malignant radius mean is: \",most_frequent_malignant_area_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つぎに3つ以上特徴量比較をするため、ペアグリッドプロットを使用します。  'radius_worst'、'perimeter_worst'と'area_worst'はいずれもworstであるため、ペアのグリッドプロットで可視化すると、当然ながら相関していることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "x=df.loc[:,['radius_worst','perimeter_worst','area_worst']]\n",
    "g=sns.PairGrid(x,diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot,cmap='Blues_d')\n",
    "g.map_upper(plt.scatter,edgecolor=\"w\")\n",
    "g.map_diag(sns.kdeplot,lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理の実装と説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDのカラムを取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カテゴリカルデータの数値化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "診断結果のカラムを取得  \n",
    "診断（M =悪性、B =良性）をmapメソッドで数値化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y=df.diagnosis \n",
    "mapping={'M':1,'B':0}\n",
    "df_y=df_y.map(mapping)\n",
    "df_y=pd.DataFrame(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量のみのデータセットを取得\n",
    "モデルで学習させるためにデータセットから目的変数を取り除いた特徴量のみのデータを作成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=df.drop(['diagnosis'],axis=1)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 標準化\n",
    "特徴量の標準化をする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols=df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#標準化：(df_x-df_x.mean())/np.std(df_x)\n",
    "#標準化を行うコードを記述\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in cols:\n",
    "    x_scaler = StandardScaler()\n",
    "    x_scaler.fit(df_x[i][:,np.newaxis])\n",
    "    df_x[i]=x_scaler.transform(df_x[i][:,np.newaxis])\n",
    "\n",
    "df_x=pd.DataFrame(df_x)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの分割\n",
    "testデータとtrainデータに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size：デフォルトは0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y,test_size=0.2, random_state=0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_trainのshapeを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_testのshapeを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニング\n",
    "交差検証を用いたグリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tuned_parameters = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.001, 0.0001]}\n",
    "    ]\n",
    "\n",
    "score = 'recall'\n",
    "clf = GridSearchCV(SVC(), #識別器\n",
    "                   tuned_parameters, #最適化したいパラメータセット\n",
    "                   scoring= '%s_weighted' % score,\n",
    "                   cv=5, # 交差検証の回数\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train.as_matrix().reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy、Recall、Precision、F1-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(gamma=0.001, C=100, probability=True,kernel='rbf')\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチでAccuracyを算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_test = y_test.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "test_pred=pd.concat([y_test, y_pred], axis=1)\n",
    "test_pred=test_pred.rename(columns={\"diagnosis\":\"test\", 0:\"pred\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP=len(test_pred[(test_pred['test'] == 1) & (test_pred['pred'] == 1)])\n",
    "FN=len(test_pred[(test_pred['test'] == 1) & (test_pred['pred'] == 0)])\n",
    "FP=len(test_pred[(test_pred['test'] == 0) & (test_pred['pred'] == 1)])\n",
    "TN=len(test_pred[(test_pred['test'] == 0) & (test_pred['pred'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn ライブラリーを使ってAccuracyを算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチでRecall（検出率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / (TP + FN)\n",
    "recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn ライブラリーを使って Recall算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_test, y_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチでPrecision（精度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn ライブラリーを使ってPrecision算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチでF1-measure（F1値）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn ライブラリーを使って F1算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC曲線　ライブラリ\n",
    "http://www.randpy.tokyo/entry/roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf =SVC(kernel='rbf', gamma=0.001, C=100,probability=True).fit(X_train, y_train)\n",
    "\n",
    "prob = clf.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds= roc_curve(y_test, prob)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## AUC　ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = np.trapz(tpr,fpr)\n",
    "print('AUC：'+str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ROC曲線　スクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test=y_test.rename(columns={'diagnosis':'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチ\n",
    "x=np.arange(101)/100\n",
    "true_rate=[]\n",
    "false_rate=[]\n",
    "for i in range(101):\n",
    "    y_pred=pd.DataFrame((prob>x[i]).astype(int)).rename(columns={0:\"pred\"})\n",
    "    pred_test=pd.concat([y_pred,y_test], axis=1)\n",
    "    tp = sum((pred_test[\"pred\"]==1)&(pred_test[\"test\"]==1))\n",
    "    fn = sum((pred_test[\"pred\"]==0)&(pred_test[\"test\"]==1))\n",
    "    fp = sum((pred_test[\"pred\"]==1)&(pred_test[\"test\"]==0))\n",
    "    tn = sum((pred_test[\"pred\"]==0)&(pred_test[\"test\"]==0))\n",
    "    true_rate.append(tp/(tp+fn))\n",
    "    false_rate.append(fp/(fp+tn))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(false_rate,true_rate)\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC スクラッチ\n",
    "AUCをライブラリで計算した値と同様の値になりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_rate1=sorted(true_rate)\n",
    "false_rate1=sorted(false_rate)\n",
    "h=true_rate1\n",
    "w=false_rate1\n",
    "\n",
    "area=0\n",
    "for i in range(100):\n",
    "    area += h[i]*(w[i+1]-w[i])\n",
    "print('AUC：'+str(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SvmModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "       \n",
    "    def model_tuning(self,X_train,X_test,y_train,y_test,tuned_parameters):        \n",
    "        score = 'f1'\n",
    "        clf = GridSearchCV(SVC(), #識別器\n",
    "                           tuned_parameters, #最適化したいパラメータセット\n",
    "                           scoring= '%s_weighted' % score,\n",
    "                           cv=5) # 交差検証の回数\n",
    "        clf.fit(X_train, y_train.as_matrix().reshape(-1,))\n",
    "        \n",
    "        dict_params=clf.best_params_\n",
    "\n",
    "        svm = SVC(gamma=dict_params['gamma'], C=dict_params['C'], probability=True,kernel=dict_params['kernel'])\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test) \n",
    "        y_pred=pd.DataFrame(y_pred)\n",
    "        y_test=y_test.reset_index().drop(\"index\", axis=1)\n",
    "        test_pred=pd.concat([y_test, y_pred], axis=1)\n",
    "        test_pred=test_pred.rename(columns={\"diagnosis\":\"test\",0:\"pred\"})\n",
    "        \n",
    "        TP=len(test_pred[(test_pred['test'] == 1) & (test_pred['pred'] == 1)])\n",
    "        FN=len(test_pred[(test_pred['test'] == 1) & (test_pred['pred'] == 0)])\n",
    "        FP=len(test_pred[(test_pred['test'] == 0) & (test_pred['pred'] == 1)])\n",
    "        TN=len(test_pred[(test_pred['test'] == 0) & (test_pred['pred'] == 0)])\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "        recall = TP / (TP + FN)\n",
    "        precision = TP / (TP + FP)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        return 'Bestスコア'+str(clf.best_score_),'Bestパラメータ'+str(clf.best_params_),'Accuracy'+str(accuracy),'Recal'+str(recall),'Precision'+str(precision),'F1'+str(f1)\n",
    "    \n",
    "    def roc_plot(self,X_train,X_test, y_train,y_test,C,gamma,kernel):\n",
    "        \n",
    "        svm =SVC(kernel=kernel, gamma=gamma, C=C,probability=True).fit(X_train, y_train)\n",
    "        prob = svm.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds= roc_curve(y_test, prob)\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(\"ROC curve\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.show()\n",
    "        \n",
    "        return 'AUC:'+ str(np.trapz(tpr,fpr))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"input/bcwd.txt\",header=None)    \n",
    "df_id=df[0] \n",
    "df_y=df[1]\n",
    "mapping={'M':1,'B':0}\n",
    "df_y=df_y.map(mapping)\n",
    "df_y=pd.DataFrame(df_y)\n",
    "df_y.columns = ['diagnosis']\n",
    "df_x=df.drop([0, 1], axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for i in range(2,32):\n",
    "    x_scaler = StandardScaler()\n",
    "    x_scaler.fit(df_x[i][:,np.newaxis])\n",
    "    df_x[i]=x_scaler.transform(df_x[i][:,np.newaxis])\n",
    "df_x=pd.DataFrame(df_x)\n",
    "# データ分割\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y,test_size=0.2, random_state=0) \n",
    "    \n",
    "tuned_parameters = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.001, 0.0001]}\n",
    "    ]\n",
    "\n",
    "model=SvmModel()\n",
    "model. model_tuning(X_train,X_test,y_train,y_test,tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.roc_plot(X_train,X_test, y_train,y_test,100,0.001,'rbf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
